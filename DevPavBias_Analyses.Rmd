---
title: "DevPavBias_Analyses"
author: "Hillary Raab"
date: "July 12, 2019"
output: 
  html_document:
      toc: yes
      toc_float:
        collapsed: false
        smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE)
library(R.matlab)
library(tidyverse)
library(tidyr)
library(psych)
library(ggplot2)
library(pander)
library(afex)
library(lsmeans)
require(lmtest)
library(psych)
#library(Hmisc) #for rcorr function 
#library(plotrix) #for std.error fxn
library(ppcor)
library(gridExtra)

library(cluster)
#library(reshape2)
#library(xtable)
#library(plyr)
#library(boot)
#library(doBy)
#library(foreach)
library(doParallel)

#Setup cluster system (define with snow, feed to doSnow, then foreach should just work!)
cl<-makeCluster(detectCores()-1)
registerDoParallel(cl)
clusterEvalQ(cl,c(library(afex)))
```


```{r set paths}
#rootDir <- getwd()
rootDir <- '/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/PIT_HillaryShivani/'
#dataDir <- file.path(rootDir,'/DATA/PIT/')
dataDir <- '/Users/hillaryraab/Box Sync/HartleyLab_SHARED/1_STUDIES/PIT_HillaryShivani/DATA/PIT/'
```


```{r load age and gender data}
### LOAD AGE DATA
PavBias <- read.csv(file.path(rootDir, "/Analyses/PIT_cov_n61.csv"))
PavBias$subjID<-as.factor(PavBias$subjID)
PavBias$z_age<-scale(PavBias$age,center=TRUE,scale=TRUE) #age as continuous variable, mean centered and scaled
PavBias$z_ageSq<-PavBias[,"z_age"]^2
PavBias$Age.Group <- factor(PavBias$Age.Group, levels=c('Child','Teen','Adult')) #order by age
levels(PavBias$Age.Group) <- c("Children","Adolescents","Adults") #rename
```

# Descriptive Statistics
Mean age for each age group (Children 8-12 years old; Adolescents 13-17 years old; Adults 18-25 years old)
```{r descriptive statistics of sample - age, warning=FALSE}
ageSample <- c("Age.Group","age")
pander(describeBy(PavBias[ageSample],group="Age.Group"))
```

Number of males and females in each age group
```{r descriptive statistics of sample - gender}
pander(count(PavBias, Age.Group,M.or.F))
```


```{r load task data and concatenate into one dataframe}
### LOAD PARTICIPANT TASK DATA
#all PIT participant IDs
studyIDAll <-  c(1,2,3,4,5,7,8,9,10,12,13,14,16:27,32,33,36:40,42:44,46:49,51:56,58,131,147:150,154,156,159:167)
studyIDAll_chr <- as.character(studyIDAll)
studyIDAll_chr <- paste(studyIDAll,"PIT",sep="")
allPIT <- data.frame()

#loop through and create allPIT data that compiles data from each subj
for(subj in 1:length(studyIDAll_chr)){
  data <- readMat(paste0(dataDir,studyIDAll_chr[subj],"/",studyIDAll[subj],"_TaskDataLearning_Session1.mat"))
  data <- as.data.frame(data)
  data <- cbind(subjID = studyIDAll[subj], data) 
allPIT <- rbind(allPIT,data)
}

#rename columns 
colnames(allPIT) <-c("subjID","trialNum","trialType","timeCue","response1Cue","response2Cue","time2target","timeTarget","keyResp","keyTime","RT","Response","corrResp","foil","targetDisplayTime","timeOutcome","ITI","Won")

#change trial type to factor
allPIT$trialType <- as.factor(allPIT$trialType)
levels(allPIT$trialType) <- c("GW","GAL","NGW","NGAL") #rename

#merge age data and task data
allPIT <- merge(allPIT,PavBias,by="subjID",all.x=TRUE)
allPIT$subjID <- as.factor(allPIT$subjID)


### REMOVE TRIALS RESPONDED EARLY
allPIT <- allPIT[allPIT$Response!=5,]
```


# Figure 2a - Tickets Won
Total number of tickets won throughout the task plotted as a function of age
```{r tickets graph}
#figure 2a
Tickets <- allPIT %>% group_by(subjID) %>% summarize(totalTickets = sum(Won, na.rm=TRUE))

#merge tickets into Pav bias df
PavBias <- merge(PavBias,Tickets,by="subjID",all.x=TRUE)


#plot tickets as a fxn of age
ticketsWon_plot <- ggplot(PavBias, aes(x=age, y=totalTickets)) + geom_point() + 
  geom_smooth(method = "glm",formula = y ~ poly(x, 2), colour="black") + 
  labs(x = "Age", y="Tickets Won") + theme_classic(base_size=20)
plot(ticketsWon_plot)
```

Model comparison for age and age-squared as predictors of total tickets. 
```{r tickets regressions}
pitMixedTicketsAge.m<-lm(totalTickets~z_age,data=PavBias)
pitMixedTicketsAgeLinPlusSq.m<-lm(totalTickets~z_age+z_ageSq,data=PavBias)

#model comparison
anova(pitMixedTicketsAge.m,pitMixedTicketsAgeLinPlusSq.m)

#best fitting model
pander(pitMixedTicketsAgeLinPlusSq.m)
```

## Cohen's f^2 for tickets won
```{r}
#z-score all measures
PavBias$z_totalTickets<-scale(PavBias$totalTickets,center=TRUE,scale=TRUE) #age as continuous variable, mean centered and scaled

#calculate f^2 for age
standardized_pitMixedTicketsAgeSq.m<-lm(z_totalTickets~z_ageSq,data=PavBias)
Rsq1 = summary(standardized_pitMixedTicketsAgeSq.m) $r.squared

standardized_pitMixedTicketsAgeLinPlusSq.m<-lm(z_totalTickets~z_age+z_ageSq,data=PavBias)
Rsq2 = summary(standardized_pitMixedTicketsAgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age on tickets won given age-squared: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r}
remove(Rsq1, Rsq2)

#calculate f^2 for age-squared
standardized_pitMixedTicketsAge.m<-lm(z_totalTickets~z_age,data=PavBias)
Rsq1 = summary(standardized_pitMixedTicketsAge.m) $r.squared

standardized_pitMixedTicketsAgeLinPlusSq.m<-lm(z_totalTickets~z_age+z_ageSq,data=PavBias)
Rsq2 = summary(standardized_pitMixedTicketsAgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age-squared on tickets won given age: `r (Rsq2-Rsq1)/(1-Rsq2)` 


# Figure 2b - Mean Accuracy
```{r mean accuracy}
#overall mean accuracy for each participant and per condition

### accuracy
#Acc_TrialType<- allPIT %>% group_by(trialType) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
#Acc_AgeTrialType <- allPIT %>% group_by(trialType,Age.Group) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
#Acc_ParAgeTrialType <- allPIT %>% group_by(trialType,Age.Group,subjID) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
##TRYING THIS OUT
Acc_ParAgeTrialType <- allPIT %>% group_by(trialType,Age.Group,subjID) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))

Acc_TrialType<- Acc_ParAgeTrialType %>% group_by(trialType) %>% summarize(meanAcc = mean(meanAcc, na.rm = TRUE))
Acc_AgeTrialType <- Acc_ParAgeTrialType %>% group_by(trialType,Age.Group) %>% summarize(meanAcc = mean(meanAcc, na.rm = TRUE))



##standard error
stdError_AgeTrialType <- Acc_ParAgeTrialType %>% group_by(trialType,Age.Group) %>% summarize(N = n(), sdAcc = sd(meanAcc, na.rm = TRUE),seAcc = sdAcc/(sqrt(N)))

Acc_AgeTrialType <- merge(Acc_AgeTrialType,stdError_AgeTrialType,by=c("trialType","Age.Group"))

#bar colors is so you can make each bar a different color in ggplot
barColors <- c("GALt","GALa","GALc","GWt","GWa","GWc","NGALt","NGALa","NGALc","NGWt","NGWa","NGWc")
Acc_AgeTrialType <- cbind(barColors,Acc_AgeTrialType)
Acc_AgeTrialType$barColors <- factor(Acc_AgeTrialType$barColors, levels=c("GWc","GWt","GWa","GALc","GALt","GALa","NGWc","NGWt","NGWa","NGALc","NGALt","NGALa")) #order by age
```

```{r accuracy from simulated choice data from participant parameter estimates}
#load simulated choice data that were generated from participant parm estimates
simData <- readMat(paste0("/Users/hillaryraab/Box Sync/Hartley Lab/Analyses/modelComparison/modelRecovery/SimulatedChoiceDataFromParticipantParms.mat"))
  simData <- as.data.frame(simData)
  
#label the columns and turn subjID into factor
colnames(simData) <-c("subjID","trialType","corrResp")
simData$subjID <- as.factor(simData$subjID)

#make sure PavBias is in order of SubjID
PavBias <- PavBias[order(PavBias$subjID),]

#repeat age group 180 times for each trial type so can concatenate w/ simData
ageGroup <- as.data.frame(PavBias$Age.Group)
ageGroup <- as.data.frame(ageGroup[rep(seq_len(nrow(ageGroup)),each=180),])
colnames(ageGroup) <- c("Age.Group")

#add age
simData <- cbind(simData, ageGroup) 

#calculate accuracy
### accuracy
SimAcc_TrialType<- simData %>% group_by(trialType) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
SimAcc_AgeTrialType <- simData %>% group_by(trialType,Age.Group) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
SimAcc_ParAgeTrialType <- simData %>% group_by(trialType,Age.Group,subjID) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))


##standard error
stdError_SimAgeTrialType <- SimAcc_ParAgeTrialType %>% group_by(trialType,Age.Group) %>% summarize(N = n(), sdAcc = sd(meanAcc, na.rm = TRUE),seAcc = sdAcc/(sqrt(N)))

SimAcc_AgeTrialType <- merge(SimAcc_AgeTrialType,stdError_SimAgeTrialType,by=c("trialType","Age.Group"))
```

# Mean Accuracy by Age Group
Data points in blush are from simulated data generated from participant parameter estimates
```{r graph accuracy by age group w param est predictions}
#blue magenta teal
PIT_AgeXTrialTypePlot_predictive <- ggplot() + 
  geom_bar(data = Acc_AgeTrialType, aes(x=trialType, y =meanAcc, fill=barColors), stat="identity", color="Black") +
  scale_fill_manual(values=c("#1860B1","#7E0F7D","#159D8B", "#B3CCF5","#BC7EBC", "#9ED9CE","#B3CCF5","#BC7EBC", "#9ED9CE","#1860B1", "#7E0F7D","#159D8B")) + 
  geom_errorbar(data = Acc_AgeTrialType, aes(x=trialType, y=meanAcc, ymin=meanAcc-seAcc, ymax=meanAcc+seAcc),width =.2, size = 1.75, color = "#4C5454") +
  facet_wrap(~Age.Group) +  #8F9C37
  geom_point(data = Acc_ParAgeTrialType, aes(x=trialType, y=meanAcc), alpha = .5) + #alpha = .3 #organge FBA971
  geom_point(data = SimAcc_AgeTrialType, aes(x=trialType, y=meanAcc), size = 4, color = "#F9C970", alpha = 1) + #data point from sim dat 8E8A95
  geom_errorbar(data = SimAcc_AgeTrialType, aes(x=trialType, y=meanAcc, ymin=meanAcc-seAcc, ymax=meanAcc+seAcc),width =0,  size = 1, color = "#F9C970") +
  theme_classic() + theme(strip.text.x = element_text(size = 20),axis.text=element_text(size=20), axis.text.x=element_text(angle=45,hjust=1), axis.title=element_text(size=26), legend.text=element_text(size=20), legend.title=element_text(size=20),legend.position="none") +
  labs(x = "Trial Type", y="Accuracy") + geom_hline(yintercept=.5, size=2, linetype="dashed", color = "black") #line at chance 

plot(PIT_AgeXTrialTypePlot_predictive)
#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/PIT_manuscript/figures/PIT_AgeXTrialTypePlot_predictive.png", plot=PIT_AgeXTrialTypePlot_predictive, dpi=300, height = 7, width = 9, units="in")
```

# Age predicts each trial type
```{r linear regression for each trial type}
#add age to the dataframe
Acc_ParAgeTrialType <- merge(Acc_ParAgeTrialType,PavBias,by="subjID",all.x=TRUE)

#run a separate regression with age predicting accuracy for each trial type
GW_age.m <- lm(meanAcc ~ z_age, subset(Acc_ParAgeTrialType,trialType == "GW"))
GAL_age.m <- lm(meanAcc ~ z_age, subset(Acc_ParAgeTrialType,trialType == "GAL"))
NGW_age.m <- lm(meanAcc ~ z_age, subset(Acc_ParAgeTrialType,trialType == "NGW"))
NGAL_age.m <- lm(meanAcc ~ z_age, subset(Acc_ParAgeTrialType,trialType == "NGAL"))

#run a separate regression with age predicting accuracy for each trial type
GW_ageSq.m <- lm(meanAcc ~ (z_age + z_ageSq), subset(Acc_ParAgeTrialType,trialType == "GW"))
GAL_ageSq.m <- lm(meanAcc ~ (z_age + z_ageSq), subset(Acc_ParAgeTrialType,trialType == "GAL"))
NGW_ageSq.m <- lm(meanAcc ~ (z_age + z_ageSq), subset(Acc_ParAgeTrialType,trialType == "NGW"))
NGAL_ageSq.m <- lm(meanAcc ~ (z_age + z_ageSq), subset(Acc_ParAgeTrialType,trialType == "NGAL"))

#compare linear and quadratic fits
anova(GW_age.m,GW_ageSq.m)
anova(GAL_age.m,GAL_ageSq.m)
anova(NGW_age.m,NGW_ageSq.m)
anova(NGAL_age.m,NGAL_ageSq.m)

#show results
pander(GW_age.m)
pander(GAL_ageSq.m)
pander(NGW_ageSq.m)
pander(NGAL_ageSq.m)
```

## F^2 for each trial type
```{r set up F^2 for trial type}
#subset trials to then z-score
GW_trials <- subset(Acc_ParAgeTrialType,trialType == "GW")
GAL_trials <- subset(Acc_ParAgeTrialType,trialType == "GAL")
NGW_trials <- subset(Acc_ParAgeTrialType,trialType == "NGW")
NGAL_trials <- subset(Acc_ParAgeTrialType,trialType == "NGAL")


#z-score all measures
GW_trials$z_meanAcc<-scale(GW_trials$meanAcc,center=TRUE,scale=TRUE) #acc as continuous variable, mean centered and scaled
GAL_trials$z_meanAcc<-scale(GAL_trials$meanAcc,center=TRUE,scale=TRUE) #acc as continuous variable, mean centered and scaled
NGW_trials$z_meanAcc<-scale(NGW_trials$meanAcc,center=TRUE,scale=TRUE) #acc as continuous variable, mean centered and scaled
NGAL_trials$z_meanAcc<-scale(NGAL_trials$meanAcc,center=TRUE,scale=TRUE) #acc as continuous variable, mean centered and scaled
```

```{r f^2 for GW}
#calculate f^2 for age
#because this is not a multiple regression, can simply use the formula R^2/(1-R^2)
standardized_GW_age.m<-lm(z_meanAcc~z_age,data=GW_trials)
Rsq1 = summary(standardized_GW_age.m) $r.squared
```
Cohen's f^2 local effect size for age on GW accuracy: `r (Rsq1)/(1-Rsq1)` 

```{r f^2 for GAL age}
remove(Rsq1)

#calculate f^2 for age
standardized_GAL_ageSq.m<-lm(z_meanAcc~z_ageSq,data=GAL_trials)
Rsq1 = summary(standardized_GAL_ageSq.m) $r.squared

standardized_GAL_ageLinPlusSq.m<-lm(z_meanAcc~z_age+z_ageSq,data=GAL_trials)
Rsq2 = summary(standardized_GAL_ageLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age on GAL accuracy given age-squared: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r f^2 for GAL age-squared}
remove(Rsq1, Rsq2)

#calculate f^2 for age-squared
standardized_GAL_age.m<-lm(z_meanAcc~z_age,data=GAL_trials)
Rsq1 = summary(standardized_GAL_age.m) $r.squared

standardized_GAL_AgeLinPlusSq.m<-lm(z_meanAcc~z_age+z_ageSq,data=GAL_trials)
Rsq2 = summary(standardized_GAL_AgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age-squared on GAL accuracy given age: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r f^2 for NGW age}
remove(Rsq1)

#calculate f^2 for age
standardized_NGW_ageSq.m<-lm(z_meanAcc~z_ageSq,data=NGW_trials)
Rsq1 = summary(standardized_NGW_ageSq.m) $r.squared

standardized_NGW_ageLinPlusSq.m<-lm(z_meanAcc~z_age+z_ageSq,data=NGW_trials)
Rsq2 = summary(standardized_NGW_ageLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age on NGW accuracy given age-squared: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r f^2 for NGW age-squared}
remove(Rsq1, Rsq2)

#calculate f^2 for age-squared
standardized_NGW_age.m<-lm(z_meanAcc~z_age,data=NGW_trials)
Rsq1 = summary(standardized_NGW_age.m) $r.squared

standardized_NGW_AgeLinPlusSq.m<-lm(z_meanAcc~z_age+z_ageSq,data=NGW_trials)
Rsq2 = summary(standardized_NGW_AgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age-squared on NGW accuracy given age: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r f^2 for NGAL age}
remove(Rsq1)

#calculate f^2 for age
standardized_NGAL_ageSq.m<-lm(z_meanAcc~z_ageSq,data=NGAL_trials)
Rsq1 = summary(standardized_NGAL_ageSq.m) $r.squared

standardized_NGAL_ageLinPlusSq.m<-lm(z_meanAcc~z_age+z_ageSq,data=NGAL_trials)
Rsq2 = summary(standardized_NGAL_ageLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age on NGAL accuracy given age-squared: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r f^2 for NGAL age-squared}
remove(Rsq1, Rsq2)

#calculate f^2 for age-squared
standardized_NGAL_age.m<-lm(z_meanAcc~z_age,data=NGAL_trials)
Rsq1 = summary(standardized_NGAL_age.m) $r.squared

standardized_NGAL_AgeLinPlusSq.m<-lm(z_meanAcc~z_age+z_ageSq,data=NGAL_trials)
Rsq2 = summary(standardized_NGAL_AgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age-squared on NGAL accuracy given age: `r (Rsq2-Rsq1)/(1-Rsq2)` 

# Supplementary Figure 1 - Learning Curves by Age Group
```{r learning curves}
#break into 15 trials for each trial type for early, mid, and late
PIT_early <- subset(allPIT,trialNum < 61)
PIT_mid <- subset(allPIT,trialNum > 60 & trialNum < 121)
PIT_late <- subset(allPIT,trialNum > 120)

#calculate mean accuracy across blocks
EarlyAcc_ParAgeTrialType <- PIT_early %>% group_by(trialType,Age.Group,subjID) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
EarlyAcc_AgeTrialType <- EarlyAcc_ParAgeTrialType %>% group_by(trialType,Age.Group) %>% summarize(meanAcc = mean(meanAcc, na.rm = TRUE))
EarlyAcc_AgeTrialType$Block <- rep("Early",length(EarlyAcc_AgeTrialType))

MidAcc_ParAgeTrialType <- PIT_mid %>% group_by(trialType,Age.Group,subjID) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
MidAcc_AgeTrialType <- MidAcc_ParAgeTrialType %>% group_by(trialType,Age.Group) %>% summarize(meanAcc = mean(meanAcc, na.rm = TRUE))
MidAcc_AgeTrialType$Block <- rep("Middle",length(MidAcc_AgeTrialType))

LateAcc_ParAgeTrialType <- PIT_late %>% group_by(trialType,Age.Group,subjID) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
LateAcc_AgeTrialType <- LateAcc_ParAgeTrialType %>% group_by(trialType,Age.Group) %>% summarize(meanAcc = mean(meanAcc, na.rm = TRUE))
LateAcc_AgeTrialType$Block <- rep("Late",length(LateAcc_AgeTrialType))

#bind early, middle, and late
BlockAcc_AgeTrialType <- rbind(EarlyAcc_AgeTrialType,MidAcc_AgeTrialType,LateAcc_AgeTrialType)

#remove old variables 
remove(EarlyAcc_AgeTrialType,MidAcc_AgeTrialType,LateAcc_AgeTrialType)

#set blocks as factor
BlockAcc_AgeTrialType$Block <- factor(BlockAcc_AgeTrialType$Block, levels=c('Early','Middle','Late')) #order by block

#add extra column so can change line type by congruent or incongruent trial type
BlockAcc_AgeTrialType$ConIncon <- "Congruent"
BlockAcc_AgeTrialType[BlockAcc_AgeTrialType$trialType %in% c('GAL','NGW'),]$ConIncon <- "Incongruent"
  
#STANDARD ERROR

#first calculate mean accuracy for each participant and each block
EarlyAcc_ParAgeTrialType$Block <- rep("Early",length(EarlyAcc_ParAgeTrialType))
MidAcc_ParAgeTrialType$Block <- rep("Middle",length(MidAcc_ParAgeTrialType))
LateAcc_ParAgeTrialType$Block <- rep("Late",length(LateAcc_ParAgeTrialType))

#bind early, middle, and late
BlockAcc_ParAgeTrialType <- rbind(EarlyAcc_ParAgeTrialType,MidAcc_ParAgeTrialType,LateAcc_ParAgeTrialType)

#remove old variables 
remove(EarlyAcc_ParAgeTrialType,MidAcc_ParAgeTrialType)

#set blocks as factor
BlockAcc_ParAgeTrialType$Block <- factor(BlockAcc_ParAgeTrialType$Block, levels=c('Early','Middle','Late')) #order by block

#compute the standard error of the mean
stdError_BlockAgeTrialType <- BlockAcc_ParAgeTrialType %>% group_by(Block,trialType,Age.Group) %>% summarize(N = n(), sdAcc = sd(meanAcc, na.rm = TRUE),seAcc = sdAcc/(sqrt(N)))

#merge avg and standard error
BlockAcc_AgeTrialType <- merge(BlockAcc_AgeTrialType,stdError_BlockAgeTrialType,by=c("trialType","Age.Group","Block"))
BlockAcc_AgeTrialType$ConIncon <- as.factor(BlockAcc_AgeTrialType$ConIncon)
```


```{r plot learning curves}
#supplementary figure 1
PIT_LearningCurve <- ggplot(data=BlockAcc_AgeTrialType, aes(x=Block,y=meanAcc,colour=trialType)) + geom_line(aes(color=trialType,group=trialType,linetype=ConIncon),size=1) +
  geom_point(aes(color=trialType)) + 
  facet_wrap(~Age.Group) +
  geom_errorbar(data = BlockAcc_AgeTrialType, aes(ymin=meanAcc-seAcc, ymax=meanAcc+seAcc),width =.2) +
  theme_classic() + theme(
    strip.text.x = element_text(size = 18),
    axis.title=element_text(size=18),
    axis.text=element_text(size=14),
    legend.text=element_text(size=16),
    legend.title=element_text(size=18)
  ) + coord_cartesian(ylim = c(.4, 1)) +
 scale_color_manual(values=c("#022F8E", '#1C70C8',"#D68F60","#C64224")) + #coral and blue
  labs(y="Accuracy",color="Trial Type",linetype="") + geom_hline(yintercept=.5, size=2, linetype="dashed", color = "black") #line at chance
plot(PIT_LearningCurve)
#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/PIT_manuscript/figures/PIT_LearningCurve.png", plot=PIT_LearningCurve, dpi=300, height = 7, width = 9, units="in")
```

# Figure 3 - Pavlovian Performance Bias Score
Calculate PIT bias as the [average of Go on GW + NGW divided by total go] PLUS [NoGo on GAL + NGAL divided by total NoGo]
```{r calculate pav performance bias}
#add presses on go to win + presses on no go to win then divide that by all presses; reward based invigoration
calculate_RewInv <- function(x){((sum(x$trialType=='GW' & x$Response=='1')) + (sum(x$trialType=='NGW' & x$Response=='1'))) / (sum(x$Response=='1'))} 

#add no presses on go to avoid + no presses on no go to avoid then divide that by all no presses; punishment-based suppression
calculate_PunSupp <- function(x){((sum(x$trialType=='GAL' & x$Response=='0')) + (sum(x$trialType=='NGAL' & x$Response=='0'))) / (sum(x$Response=='0'))} 

PavBias <- PavBias[order(PavBias$subjID),]

PavBias$RewInv <- by(data = allPIT, INDICES = allPIT$subjID, FUN = calculate_RewInv)

PavBias$PunSupp <- by(data = allPIT, INDICES = allPIT$subjID, FUN = calculate_PunSupp)

#calculate Pavlovian performance bias by averaging reward-based invigoration and punishment-based suppression
PavBias$PavPerBias <- (PavBias$RewInv + PavBias$PunSupp)/2
```


```{r Pav performance bias regression, echo=FALSE}
PavPerBiasAge.m<-lm(PavPerBias~z_age,data=PavBias)
PavPerBiasAgePlusAgeSq.m<-lm(PavPerBias~z_age+z_ageSq,data=PavBias)

#model comparison
anova(PavPerBiasAge.m,PavPerBiasAgePlusAgeSq.m)

#best fitting model
pander(PavPerBiasAgePlusAgeSq.m)
```

```{r plot accuracy for Pav Performance Bias Quadratic, echo=FALSE}
#figure 3.
#plot model free pav bias as a fxn of ageSq
pavPerformanceBias_plot_line <- ggplot(PavBias, aes(x=age, y=PavPerBias)) + geom_point() + geom_smooth(data=PavBias, method = "lm",formula = y ~ poly(x, 2), colour="black") + labs(x = "Age", y="Pavlovian Performance Bias") +
  geom_hline(yintercept=.5, linetype="dashed", color = "black") +
  theme_classic(base_size=20)
plot(pavPerformanceBias_plot_line)
```

## Cohen's f^2 for Pavlovian Performance Bias
```{r}
remove(Rsq1, Rsq2)

#z-score all measures
PavBias$z_PavPerBias<-scale(PavBias$PavPerBias,center=TRUE,scale=TRUE) #age as continuous variable, mean centered and scaled

#calculate f^2 for age
standardized_PavPerBiasAgeSq.m<-lm(z_PavPerBias~z_ageSq,data=PavBias)
Rsq1 = summary(standardized_PavPerBiasAgeSq.m) $r.squared

standardized_PavPerBiasAgeLinPlusSq.m<-lm(z_PavPerBias~z_age+z_ageSq,data=PavBias)
Rsq2 = summary(standardized_PavPerBiasAgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age on Pav Performance Bias given age-squared: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r}
remove(Rsq1, Rsq2)

#calculate f^2 for age-squared
standardized_PavPerBiasAge.m<-lm(z_PavPerBias~z_age,data=PavBias)
Rsq1 = summary(standardized_PavPerBiasAge.m) $r.squared

standardized_PavPerBiasAgeLinPlusSq.m<-lm(z_PavPerBias~z_age+z_ageSq,data=PavBias)
Rsq2 = summary(standardized_PavPerBiasAgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age-squared on Pav Performance Bias given age: `r (Rsq2-Rsq1)/(1-Rsq2)` 


# Supplementary figure 2 - Relationship between Punishment Suppression and Reward Invigoration Pav Performance bias
```{r plot punishment suppression and reward invigoration}
#supplementary figure 2
RewInv_PunSup_plot <- ggplot(PavBias, aes(x=RewInv, y=PunSupp, color = age)) + geom_point() + geom_smooth(data=PavBias, method = "lm",formula = y ~ poly(x, 1), colour="black") + labs(x = "Reward Invigoration Bias", y="Punishment Suppression Bias") +
  theme_classic(base_size=20) + coord_fixed(ratio=1, ylim = c(.3, 1.01), xlim = c(.3, 1.01), expand=FALSE) 
plot(RewInv_PunSup_plot)

#relationship between two Pavlovian performance bias components
cor.test(PavBias$RewInv,PavBias$PunSupp,method=c("pearson"))

#partial correlation b/n two Pavlovian performance bias components, controlling for age
pcor.test(PavBias$RewInv,PavBias$PunSupp,PavBias$age,method=c("pearson"))
```

# Supplementary Table 1 - Valence X Action Logistic Regression Analysis
## Correct choice mixed effects model with subject specific intercepts but not slopes
```{r setup regressions}

#add extra columns for valence and action; convert to factors
#1 Go; -1 NoGo
allPIT$action <- "1"
allPIT[allPIT$trialType %in% c('NGW','NGAL'),]$action <- "-1"
allPIT$action <- as.factor(allPIT$action)

#1 Win; -1 Avoid Losing
allPIT$valence <- "1"
allPIT[allPIT$trialType %in% c('GAL','NGAL'),]$valence <- "-1"
allPIT$valence <- as.factor(allPIT$valence)

#set as factor
allPIT$corrResp <- as.factor(allPIT$corrResp)#correctChoice as 1 and 0
```


```{r Valence Action regression analyses with random intercepts}
#not including age
pitMixedVxA.m<-mixed(corrResp~valence*action+(1|subjID),data=allPIT,
                                         control=glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=100000)),family="binomial", method="LRT",cl=cl)

#with age
pitMixedVxAxAge.m <- mixed(corrResp~valence*action*z_age+(1|subjID),data=allPIT, control=glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=100000)),family="binomial", method="LRT",cl=cl)

#with age and age-squared
pitMixedVxAxAgeAgeSq.m <- mixed(corrResp~valence*action*(z_age+z_ageSq)+(1|subjID),data=allPIT, control=glmerControl(optimizer = "bobyqa", optCtrl=list(maxfun=100000)),family="binomial", method="LRT",cl=cl)

#model comparison
anova(pitMixedVxA.m,pitMixedVxAxAge.m)
anova(pitMixedVxAxAge.m,pitMixedVxAxAgeAgeSq.m)

#best fitting model
summary(pitMixedVxAxAgeAgeSq.m)
```

# Computational Modeling Results
I compared a set of nested models that included 1 learning rate, 2 learning rates, squashed softmax, Go Bias, Pav Bias, Reward Sensitivity, and Punishment Sensitivity. The model that fit best according to median AIC was Go+Pav+RewSens using the squashed softmax choice fxn.

These data were fit using Matlab fmincon with the following bounds on the parameters:
learning rate and squashed softmax: 0 to 1
Go Bias: -inf to inf
Pav Bias, RewSens, PunSens: 0 to inf

The following priors were used:
	log(betapdf(alphaPos,1.1,1.1));
  log(betapdf(alphaNeg,1.1,1.1))
  log(betapdf(squashedSoftmax,1.1,1.1));
	log(normpdf(gobias,0,1));
  log(gampdf(pavbias,2,3));
  log(gampdf(posRewardSens,2,3));
  
  
Here I examined linear and quadratic age-related changes in the parameter estimates. All regressions were run using z-scored age and age-squared. First I ran a regression testing the effect of age on the parameter and then a model testing age and age-squared. An anova was used to compare which model provided a better fit.

```{r, load parameter estimates, echo=FALSE, message=FALSE, warning=FALSE}
parameterEstimates_squashedSoftmax <- read_csv("/Users/hillaryraab/Box Sync/Hartley Lab/Analyses/modelComparison/ModelsWithMAPremovedForAICcalculation/Fits_n61_infinite_priors/Fit_n61_BestModel_GoPavRewSens_prior.csv", (header = TRUE)) 

#load age covariate
parameterEstimates_squashedSoftmax$age <- PavBias$age
parameterEstimates_squashedSoftmax$z_age <- PavBias$z_age
parameterEstimates_squashedSoftmax$z_ageSq <- PavBias$z_ageSq
```

## Table 1 - Mean parameter estimates 
```{r initialize median param est}
childData <- subset(parameterEstimates_squashedSoftmax, age < 13)
teenData <- subset(parameterEstimates_squashedSoftmax, age >= 13 & age < 18)
adultData <- subset(parameterEstimates_squashedSoftmax, age >= 18)
```

Child Estimates mean; Quartile: 0%  25%  50%  75%  100%):  
Lapse rate (xi): `r mean(childData$squashedSoftmax)` ; `r quantile(childData$squashedSoftmax)`  
Learning rate (ep): `r mean(childData$alpha)` ; `r quantile(childData$alpha)`  
Go bias (b): `r mean(childData$GoBias)` ; `r quantile(childData$GoBias)`  
Pav bias (pi): `r mean(childData$PavBias)` ; `r quantile(childData$PavBias)`  
Reward sensitivity (rhoRew): `r mean(childData$RewSens)` ; `r quantile(childData$RewSens)`  


Adolescent Estimates mean(sem):  
Lapse rate (xi): `r mean(teenData$squashedSoftmax)` ; `r quantile(teenData$squashedSoftmax)`  
Learning rate (ep): `r mean(teenData$alpha)` ; `r quantile(teenData$alpha)`  
Go bias (b): `r mean(teenData$GoBias)` ; `r quantile(teenData$GoBias)`  
Pav bias (pi): `r mean(teenData$PavBias)` ; `r quantile(teenData$PavBias)`  
Reward sensitivity (rhoRew): `r mean(teenData$RewSens)` ; `r quantile(teenData$RewSens)`  


Adult Estimates mean(sem):  
Lapse rate (xi): `r mean(adultData$squashedSoftmax)` ; `r quantile(adultData$squashedSoftmax)`  
Learning rate (ep): `r mean(adultData$alpha)` ; `r quantile(adultData$alpha)`  
Go bias (b): `r mean(adultData$GoBias)` ; `r quantile(adultData$GoBias)`  
Pav bias (pi): `r mean(adultData$PavBias)` ; `r quantile(adultData$PavBias)`  
Reward sensitivity (rhoRew): `r mean(adultData$RewSens)` ; `r quantile(adultData$RewSens)`  



#  Supplementary figure 3 -Parameter Estimates by Age
No effect of age on alpha
```{r, echo=FALSE}
#plot alpha as a fxn of age
alpha_age <- ggplot(parameterEstimates_squashedSoftmax, aes(x=age, y=alpha)) + geom_point() + geom_smooth(data=parameterEstimates_squashedSoftmax, method = "glm",formula = y ~ poly(x, 1), colour="black") + labs(x = "Age", y="Parameter Estimate") + ggtitle("Learning Rate") +
  theme_classic(base_size=10) + theme(plot.title = element_text(hjust = 0.5))
#plot(alpha_age)
```

No effect of age on the softmax
```{r, echo=FALSE}
#plot beta as a fxn of age
ss_age <- ggplot(parameterEstimates_squashedSoftmax, aes(x=age, y=squashedSoftmax)) + geom_point() + geom_smooth(data=parameterEstimates_squashedSoftmax, method = "glm",formula = y ~ poly(x, 1), colour="black") + labs(x = "Age", y="Parameter Estimate") + ggtitle("Lapse Rate") +
  theme_classic(base_size=10) + theme(plot.title = element_text(hjust = 0.5))
#plot(ss_age)
```

Sig. age-squared effect on Go bias
```{r, echo=FALSE}
#plot go as a fxn of age
go_age <- ggplot(parameterEstimates_squashedSoftmax, aes(x=age, y=GoBias)) + geom_point() + geom_smooth(data=parameterEstimates_squashedSoftmax, method = "glm",formula = y ~ poly(x, 2), colour="black") + labs(x = "Age", y="Parameter Estimate") + ggtitle("Go Bias") +
  theme_classic(base_size=10) + theme(plot.title = element_text(hjust = 0.5))
#plot(go_age)
```

Sig. age and age-squared effect on Pav bias
```{r, echo=FALSE}
#plot pav as a fxn of age squared
pav_age <- ggplot(parameterEstimates_squashedSoftmax, aes(x=age, y=PavBias)) + geom_point() + geom_smooth(data=parameterEstimates_squashedSoftmax, method = "glm",formula = y ~ poly(x, 2), colour="black") + labs(x = "Age", y="Parameter Estimate") + ggtitle("Pavlovian Bias") +
  theme_classic(base_size=10) + theme(plot.title = element_text(hjust = 0.5))
#plot(pav_age)
```

Sig. age effect on Rew Sens
```{r, echo=FALSE}
#plot reinf sensitivity as a fxn of age
reinf_age <- ggplot(parameterEstimates_squashedSoftmax, aes(x=age, y=RewSens)) + geom_point() + geom_smooth(data=parameterEstimates_squashedSoftmax, method = "glm",formula = y ~ poly(x, 1), colour="black") + labs(x = "Age", y="Parameter Estimate") + ggtitle("Reinforcement Sensitivity") +
  theme_classic(base_size=10) + theme(plot.title = element_text(hjust = 0.5))
parmEstFigs <- grid.arrange(alpha_age,ss_age, go_age,pav_age,reinf_age,nrow = 1)

#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/PIT_manuscript/figures/ModelParmEst.png", plot=parmEstFigs, dpi=300, height = 3, width = 13, units="in")
```



```{r age regressions, echo=FALSE}
alphaAge.m<-lm(alpha~z_age,data=parameterEstimates_squashedSoftmax)
squashedSoftmaxAge.m<-lm(squashedSoftmax~z_age,data=parameterEstimates_squashedSoftmax)
goAge.m<-lm(GoBias~z_age,data=parameterEstimates_squashedSoftmax)
pavAge.m<-lm(PavBias~z_age,data=parameterEstimates_squashedSoftmax)
rewAge.m<-lm(RewSens~z_age,data=parameterEstimates_squashedSoftmax)
```


```{r age + ageSq regressions, echo=FALSE}
alphaAgePlusAgeSq.m<-lm(alpha~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
squashedSoftmaxAgePlusAgeSq.m<-lm(squashedSoftmax~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
goAgePlusAgeSq.m<-lm(GoBias~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
pavAgePlusAgeSq.m<-lm(PavBias~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
rewAgePlusAgeSq.m<-lm(RewSens~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
```

## Model Comparison ANOVA: Age vs. Age+Age^2
```{r, ANOVA to compare models to compare age}

anova(alphaAge.m,alphaAgePlusAgeSq.m)
anova(squashedSoftmaxAge.m,squashedSoftmaxAgePlusAgeSq.m)
anova(goAge.m,goAgePlusAgeSq.m)
anova(pavAge.m,pavAgePlusAgeSq.m)
anova(rewAge.m,rewAgePlusAgeSq.m)
```

## Regression Results Age
```{r regression results age, echo=FALSE}
pander(alphaAge.m)
pander(squashedSoftmaxAge.m)
pander(rewAge.m)
``` 

## Regression Results Age + Age Squared
```{r regression results age+age^2, echo=FALSE}
pander(goAgePlusAgeSq.m)
pander(pavAgePlusAgeSq.m)
``` 

## Correlation w/ Pavlovian performance bias
```{r, echo=FALSE}
#merge Pav bias and Pav performance bias 
PavBias <- PavBias[order(PavBias$subjID),]
parameterEstimates_squashedSoftmax <- parameterEstimates_squashedSoftmax[order(parameterEstimates_squashedSoftmax$subjID),]
parameterEstimates_squashedSoftmax$PavPerBias<-PavBias$PavPerBias

cor.test(parameterEstimates_squashedSoftmax$PavPerBias,parameterEstimates_squashedSoftmax$PavBias,alternative=c("greater"),method=c("spearman"))
```

## Cohen's f^2 for all parameter estimates
### Lapse Rate
```{r}
#z-score all measures
parameterEstimates_squashedSoftmax$z_squashedSoftmax<-scale(parameterEstimates_squashedSoftmax$squashedSoftmax,center=TRUE,scale=TRUE) #age as continuous variable, mean centered and scaled

#calculate f^2 for age
#because this is not a multiple regression, can simply use the formula R^2/(1-R^2)
standardized_squashedSoftmaxAge.m<-lm(z_squashedSoftmax~z_age,data=parameterEstimates_squashedSoftmax)
Rsq1 = summary(standardized_squashedSoftmaxAge.m) $r.squared
```
Cohen's f^2 local effect size for age on squashed softmax: `r (Rsq1)/(1-Rsq1)` 

### Learning Rate
```{r}
#z-score all measures
parameterEstimates_squashedSoftmax$z_alpha<-scale(parameterEstimates_squashedSoftmax$alpha,center=TRUE,scale=TRUE) #age as continuous variable, mean centered and scaled

#calculate f^2 for age
#because this is not a multiple regression, can simply use the formula R^2/(1-R^2)
standardized_alphaAge.m<-lm(z_alpha~z_age,data=parameterEstimates_squashedSoftmax)
Rsq1 = summary(standardized_alphaAge.m) $r.squared
```
Cohen's f^2 local effect size for age on learning rate: `r (Rsq1)/(1-Rsq1)` 

### Go Bias
```{r}
#z-score all measures
parameterEstimates_squashedSoftmax$z_GoBias<-scale(parameterEstimates_squashedSoftmax$GoBias,center=TRUE,scale=TRUE) #age as continuous variable, mean centered and scaled

#calculate f^2 for age
standardized_GoBiasAgeSq.m<-lm(z_GoBias~z_ageSq,data=parameterEstimates_squashedSoftmax)
Rsq1 = summary(standardized_GoBiasAgeSq.m) $r.squared

standardized_GoBiasAgeLinPlusSq.m<-lm(z_GoBias~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
Rsq2 = summary(standardized_GoBiasAgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age on go bias given age-squared: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r}
remove(Rsq1, Rsq2)

#calculate f^2 for age-squared
standardized_GoBiasAge.m<-lm(z_GoBias~z_age,data=parameterEstimates_squashedSoftmax)
Rsq1 = summary(standardized_GoBiasAge.m) $r.squared

standardized_GoBiasAgeLinPlusSq.m<-lm(z_GoBias~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
Rsq2 = summary(standardized_GoBiasAgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age-squared on GoBias given age: `r (Rsq2-Rsq1)/(1-Rsq2)` 

### Pav Bias
```{r}
#z-score all measures
parameterEstimates_squashedSoftmax$z_PavBias<-scale(parameterEstimates_squashedSoftmax$PavBias,center=TRUE,scale=TRUE) #age as continuous variable, mean centered and scaled

#calculate f^2 for age
standardized_PavBiasAgeSq.m<-lm(z_PavBias~z_ageSq,data=parameterEstimates_squashedSoftmax)
Rsq1 = summary(standardized_PavBiasAgeSq.m) $r.squared

standardized_PavBiasAgeLinPlusSq.m<-lm(z_PavBias~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
Rsq2 = summary(standardized_PavBiasAgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age on pav bias given age-squared: `r (Rsq2-Rsq1)/(1-Rsq2)` 

```{r}
remove(Rsq1, Rsq2)

#calculate f^2 for age-squared
standardized_PavBiasAge.m<-lm(z_PavBias~z_age,data=parameterEstimates_squashedSoftmax)
Rsq1 = summary(standardized_PavBiasAge.m) $r.squared

standardized_PavBiasAgeLinPlusSq.m<-lm(z_PavBias~z_age+z_ageSq,data=parameterEstimates_squashedSoftmax)
Rsq2 = summary(standardized_PavBiasAgeLinPlusSq.m) $r.squared
```
Cohen's f^2 local effect size for age-squared on PavBias given age: `r (Rsq2-Rsq1)/(1-Rsq2)` 


### Reinforcement Sensitivity
```{r}
#z-score all measures
parameterEstimates_squashedSoftmax$z_RewSens<-scale(parameterEstimates_squashedSoftmax$RewSens,center=TRUE,scale=TRUE) #age as continuous variable, mean centered and scaled

#calculate f^2 for age
standardized_RewSensAge.m<-lm(z_RewSens~z_age,data=parameterEstimates_squashedSoftmax)
Rsq1 = summary(standardized_RewSensAge.m) $r.squared
```
Cohen's f^2 local effect size for age on reinforcement sensitivity: `r (Rsq1)/(1-Rsq1)` 


# Supplementary Table 4 - Response Time Analysis
This analysis is as stated in Swart et al., 2017. All Go responses are included as in the aforementioned paper and RT is log-transformed. RT is modeled w/ action, valence, age, and (age + age-squared) as predictors.
```{r RT analysis}
#take all Go response (correct + incorrect)
PIT_RTall <- subset(allPIT, (Response == 1))

#log transform RT
PIT_RTall$RT_log <- log(PIT_RTall$RT)

#add extra columns for valence and action; convert to factors
#1 Go; -1 NoGo
PIT_RTall$Action <- "1"
PIT_RTall[PIT_RTall$trialType %in% c('NGW','NGAL'),]$Action <- "-1"
PIT_RTall$Action <- as.factor(PIT_RTall$Action)

#1 Win; -1 Avoid Losing
PIT_RTall$Valence <- "1"
PIT_RTall[PIT_RTall$trialType %in% c('GAL','NGAL'),]$Valence <- "-1"
PIT_RTall$Valence <- as.factor(PIT_RTall$Valence)

#log-transformed mixed-effects model
pitRTlog.m<-mixed(RT_log~Valence*Action + (1|subjID),data=PIT_RTall,control=lmerControl(optCtrl=list(maxfun=100000)),method="LRT")
pitRTageLinlog.m<-mixed(RT_log~Valence*Action*z_age + (1|subjID),data=PIT_RTall,control=lmerControl(optCtrl=list(maxfun=100000)),method="LRT")
pitRTageLinSqlog.m<-mixed(RT_log~Valence*Action*(z_age+z_ageSq) + (1|subjID),data=PIT_RTall,control=lmerControl(optCtrl=list(maxfun=100000)),method="LRT")
anova(pitRTlog.m,pitRTageLinlog.m)
anova(pitRTageLinlog.m,pitRTageLinSqlog.m)
summary(pitRTageLinlog.m)
```

# Supplementary Figure 4 - Posterior Predictive Check
```{r accuracy from simulated choice data from participant parameter estimates for all 9 models}
#load simulated choice data that were generated from participant parm estimates
simData <- read.csv("/Users/hillaryraab/Box Sync/Hartley Lab/Analyses/modelComparison/modelPredictions/simAccuracy_all.csv", header = FALSE)
  simData <- as.data.frame(simData)
  
#label the columns and turn subjID into factor
colnames(simData) <-c("model","simNum","trialNum","trialType","corrResp")
simData$simNum <- as.factor(simData$simNum)
simData$model <- as.factor(simData$model)
simData$trialType <- as.factor(simData$trialType)
levels(simData$trialType) <- c("GW","GAL","NGW","NGAL") #rename

#make sure PavBias in order of subjID
PavBias <- PavBias[order(PavBias$subjID),]

#repeat age group 180 times for each trial type so can concatenate w/ simData
ageGroup <- as.data.frame(PavBias$Age.Group)
ageGroup <- as.data.frame(ageGroup[rep(seq_len(nrow(ageGroup)),each=180),])
colnames(ageGroup) <- c("Age.Group")

#add age
simData <- cbind(simData, ageGroup) 

#calculate accuracy
### accuracy
SimAcc_TrialType<- simData %>% group_by(model,trialType) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
SimAcc_AgeTrialType <- simData %>% group_by(model,trialType,Age.Group) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))
SimAcc_ParAgeTrialType <- simData %>% group_by(model,trialType,Age.Group,simNum) %>% summarize(meanAcc = mean(corrResp, na.rm = TRUE))


##standard error
stdError_SimAgeTrialType <- SimAcc_ParAgeTrialType %>% group_by(model,trialType,Age.Group) %>% summarize(N = n(), sdAcc = sd(meanAcc, na.rm = TRUE),seAcc = sdAcc/(sqrt(N)))

SimAcc_AgeTrialType <- merge(SimAcc_AgeTrialType,stdError_SimAgeTrialType,by=c("model","trialType","Age.Group"))
```

```{r predictions from the 9 models}
#predictions from the models using the parameter values estimated from the 61 participants
#plotted on top of participant data

levels(SimAcc_AgeTrialType$model) <- c("RW","+ Go","+ Pav","+ Go + Pav","+ Reinforcement Sens","+ Go + Reinforcement Sens", "+ Pav + Reinforcement Sens","+ Go + Pav + Reinforcement Sens", "+ Go + Pav + RewSens + PunSens") #rename

Model_predictions <- ggplot() + 
  
  #participant data
  geom_bar(data = Acc_AgeTrialType, aes(x=trialType, y =meanAcc, fill=barColors), stat="identity", color="Black", show.legend = FALSE) +
  scale_fill_manual(values=c("#1860B1","#7E0F7D","#159D8B", "#B3CCF5","#BC7EBC", "#9ED9CE","#B3CCF5","#BC7EBC", "#9ED9CE","#1860B1", "#7E0F7D","#159D8B")) + 
  geom_errorbar(data = Acc_AgeTrialType, aes(x=trialType, y=meanAcc, ymin=meanAcc-seAcc, ymax=meanAcc+seAcc),width =.2,    size = 1.75, color = "#4C5454") +
  
  #line at chance
  geom_hline(yintercept=.5, size=2, linetype="dashed", color = "black") + 
  
  #add points for simulated data predictions
  geom_point(data = SimAcc_AgeTrialType, aes(x=trialType, y =meanAcc, colour=model), stat="identity", size = 4) +
  facet_wrap(~Age.Group) +
  scale_color_brewer(palette="YlOrRd") +
  
  #add border around best fitting model
  geom_point(data = subset(SimAcc_AgeTrialType, model == "+ Go + Pav + Reinforcement Sens"), shape = 21, stroke = 1.25, aes(x=trialType, y =meanAcc), stat="identity", color = "black", size = 4) +
  
  #geom_point(data = subset(SimAcc_AgeTrialType, model == "+ Go + Pav + Reinforcement Sens"), aes(x=trialType, y =meanAcc), stat="identity", color = "#F2E94E", size = 4) +
  theme_classic() + theme(strip.text.x = element_text(size = 20),axis.text=element_text(size=20), axis.text.x=element_text(angle=45,hjust=1), axis.title=element_text(size=26)) +
  #add labels
  labs(x = "Trial Type", y="Accuracy", colour = "Model") 

plot(Model_predictions)
#ggsave(filename="/Users/hillaryraab/Box Sync/Hartley Lab/PIT_manuscript/figures/ModelPredictions.png", plot=Model_predictions, dpi=300, height = 7, width = 13, units="in")
```

